%\documentclass[a4paper]{article}
\documentclass{IEEEtran}

%\usepackage{times}
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{tabularx}

% Any macro definitions you would like to include
% These are not defined in the style file, because they don't begin
% with \bmva, so they might conflict with the user's own macros.
% The \bmvaOneDot macro adds a full stop unless there is one in the
% text already.
\def\eg{\emph{e.g.,}}
\def\ie{\emph{i.e.,}}
\def\etal{\emph{et al.}}
\def\vs{\emph{vs.}}

% macros for referencing figures, tables, equations and sections
\newcommand{\fref}[1]{Figure~\ref{#1}}
\newcommand{\eref}[1]{(\ref{#1})}
\newcommand{\tref}[1]{Table~\ref{#1}}
\newcommand{\sref}[1]{Section~\ref{#1}}
\newcommand{\aref}[1]{Algorithm~\ref{#1}}
\newcommand{\emptybox}[2]{\framebox[#1][l]{\rule[#2]{0pt}{0pt}}}

% maths macros
\def\G{G}
\def\Gx{G_x}
\def\Gy{G_y}
\def\Gxx{G_{xx}}
\def\Gxy{G_{xy}} \def\Gyx{G_{yx}}
\def\Gyy{G_{yy}}
\def\Ix{I_x}
\def\Iy{I_y}
\def\Ixsqr{I_{x^2}}
\def\Iysqr{I_{y^2}}
\def\Ixx{I_{xx}}
\def\Ixy{I_{xy}}
\def\Iyy{I_{yy}}
\def\dtcwt{DT-$\mathbb{C}$WT}

\def\deg{\ensuremath{^\circ}}
\def\rad{\ensuremath{\text{radians}}}
\def\by{\ensuremath{\times}}

% lengths for image sizes
\newlength{\qtrcol}\setlength{\qtrcol}{0.24\columnwidth}
\newlength{\halfcol}\setlength{\halfcol}{0.48\columnwidth}

% command for adding inline comment to text
\newcommand{\comment}[1]{}

% define title here so headers are updated, too
\def\ttl{Analysing Curvilinear Structures in Images}
\title{\ttl}
\author{Authors}

% define path to figures
\def\figroot{./figs}
\def\figpath{\figroot}


%-------------------------------------------------------------------------
% Document starts here
\begin{document}

\tableofcontents\clearpage

\maketitle

\begin{abstract}
Estimating orientation of image structure underpins applications including digital mammography, retinography and fingerprint analysis. We consider different choices of filter bank including those based on first and second derivatives, efficient Haar-like features and the Dual Tree Complex Wavelet Transform. We then investigate how standard regressors (linear regression, Boosting and Random Forests) may be adapted to use the responses to these filter banks in order to predict orientation of image structure. For a quantitative evaluation, we use synthetic images based on mammograms and the publicly available DRIVE database of retinal images, and show that Random Forests and the wavelet transform offer superior accuracy though at a cost in efficiency. Qualitative results are also presented for real mammograms and fingerprint images.
\end{abstract}

\input{citations.tex}


\section{Introduction}
% State the problem, and its impact on all stakeholders (those directly affected, and society at large e.g. the social and economic impact of treating the disease)
A curvilinear structure in an image appears as a ribbon or bar of finite width that is distinguishable from the surrounding structure, with a cross-sectional profile that is repeated along a linear, though not necessarily straight, path (\fref{f:line_examples}).

%What are their general characteristics?
%Defined locally by their cross-sectional profile and orientation, and assumed to extend in at least one direction normal to the profile (as opposed to a blob).

Detecting and measuring the properties of curvilinear structures in images is useful for many reasons~\cite{Ayres_Rangayyan_JEI07}:

\begin{itemize}
\item detecting distinctive patterns of vessels and fibrous tissue can improve quality of life and reduce costs associated with treating diseases such as retinopathy (\sref{s:retinopathy}) and breast cancer (\sref{s:mammography}) in advanced stages by aiding early diagnosis and treatment; %
\item spotting cracks and other similar defects in manufactured items such as roads, eggs can reduce costs associated with waste; %
\item biometrics based on ridge patterns in fingerprints~\cite{}, or the veins of the finger~\cite{} or hand~\cite{}, can bring criminals to justice and prevent further crime, or enhance the usability of technology by controlling access to sensitive data; %
\item detecting roads, railways and rivers in aerial photography can help to build maps automatically for applications such as providing relief in remote areas following a natural disaster.
\end{itemize}


\subsection{Aims and Objectives}

\begin{figure}[t]
\centering
\begin{tabular}{@{}c c c@{}}
\includegraphics[width=0.3\columnwidth]{\figpath/retina/02_test} &
\includegraphics[width=0.3\columnwidth]{\figpath/retina/02_segmentation_gabor_inv.png} &
\includegraphics[width=0.3\columnwidth]{\figpath/retina/002_orientation_masked} \\
%\includegraphics[height=0.15\textheight]{\figpath/retina/002_abs_error} \\
(a) & (b) & (c) \\
\noalign{\smallskip}
\end{tabular}
%
\caption{Estimating orientation in retinography: %
(a) input image; %
(b) segmentation of vessels by random forest classification of Gabor features; %
(c) orientation (indicated by colour) estimated using random regression over Gabor~features. The mask was not used to estimate orientation. %
%(c) magnitude of error (note the regions of high error at points of bifurcation.)
}
\label{f:retinography}
\end{figure}

% Specific aims of the study
Given an image, our aim is to determine where any linear structures exist in the image, and to measure values that correspond to low-level properties such as orientation, width, and cross-sectional profile. Although these properties form the basis of higher level, application-specific analysis (classifying structure as \emph{road}, \emph{rail} or \emph{river} in aerial photographs, for example), our focus is purely on computing the local attributes as accurately and robustly as possible; by improving the accuracy of the values we estimate, it follows logically that performance should improve for all higher level analysis methods that use these values as inputs.\footnote{Any algorithm that does not benefit from better input should be regarded with suspicion.}

%For example, any method to move from a map of vessel probabilities and predicted orientations in a retinograms, to an explicit grouping of pixels that belong to individual vessels, is likely to benefit from a priori knowledge of the spatial arrangement vessels in that image class and the physical model of how vessels grow and bifurcate. Such a method will therefore be very different from that needed to group a similar set of local information into the road, rivers etc present in an image for aerial analysis

With this focus, we have two objectives: extract, at every image location, structural information that is rich enough to capture the underlying image properties yet sparse enough to be computed efficiently; and combine this raw local information to predict output values of interest (such as orientation).


% Review other people's attempts at solving the problem, and why they are found wanting
\subsection{Related Work}
\input{related_work}

% Describe what we do, and why it is better than preceding works
\subsection{Our Contributions}
\input{our_contributions}




\clearpage
\section{Input Image Features}
\subsection{Filtering}
\label{s:filtering}
In this section we consider the theoretical requirements of a suitable filter bank, keeping foremost in our mind the application in which the responses will be used. That is the set of responses for any given structure pixel should be distinguishable from that of any background pixel; the filters should be directionally selective to predict orientation; likewise to predict structure width the responses should be selective across scale.

\begin{figure}[t]
\centering
\begin{tabular}{@{}c c c c@{}} % @{} removes padding around the edge of the table
\includegraphics[width=0.2\columnwidth]{figs/filtering/Gx} &
\includegraphics[width=0.2\columnwidth]{figs/filtering/Gxx} &
\includegraphics[width=0.2\columnwidth]{figs/filtering/Gxy} &
\includegraphics[width=0.2\columnwidth]{figs/filtering/Gxx-Gyy} \\
(a) & (b) & (c) & (d) \\
\noalign{\smallskip}
%
\includegraphics[width=0.2\columnwidth]{figs/filtering/mono_b} &
\includegraphics[width=0.2\columnwidth]{figs/filtering/mono_hx} &
\includegraphics[width=0.2\columnwidth]{figs/filtering/dt_cwt_r4} &
\includegraphics[width=0.2\columnwidth]{figs/filtering/dt_cwt_c4} \\
(e) & (f) & (g) & (h) \\
\noalign{\smallskip}
\end{tabular}
%
\caption{(a)~First derivatives $\Gx = \Gy^T$; (b-d)~Second derivatives, $\Gxx = \Gyy^T$, $\Gxy$; and $\Gxx-\Gyy$; (e,f)~Monogenic signal filters $B$ and $h_x = h_y^T$; (g,h)~Real and complex responses of the \dtcwt~ $15^\circ$ subband.}
\label{f:filters}
\end{figure}

\subsubsection{Gaussian derivatives}
\label{s:filtering_secondderivs}
%
We start by considering probably the most commonly used set of filters for linear structure detection (certainly within the context of vessel segmentation in medical images): derivatives of a Gaussian kernel.

Gaussian first derivatives - edge detection. Explain second derivatives.
%
The directional second-order derivative of a Gaussian generates an even (\ie~symmetric) image filter that resembles a bar or ridge feature. Like their first-order counterparts, second-order derivatives are steerable though they require three rather than two basis filters. The second-order basis filters are not separable, though a different formulation generates three equivalent basis filters -- $\Gxx$, $\Gyy$ and $\Gxy$ (\fref{f:filters_secondderivs}) -- that are. The response to a second-order derivative is given by
%
\begin{equation}
R(\theta) = \Ixx \cos^2(\theta) + \Iyy \sin^2(\theta) + \Ixy \sin(2\theta)
\label{e:secondderivs_response}
\end{equation}
%
\noindent where $\Ixx = \Gxx\ast I$, $\Iyy = \Gyy\ast I$ and $\Ixy = \Gxy\ast I$ are the responses to the three separable filters. This response function has four stationary points in the range $[0,2\pi)$, occuring at
%
\begin{equation}
\theta = \frac{1}{2} \tan^{-1}\left( \frac{2\Ixy}{\Ixx-\Iyy} \right).
\label{e:secondderivs_orientation}
\end{equation}
%
\noindent Two of these points, separated by $\pi\,\rad$ because the filter is rotationally symmetric, correspond to the directions in which the filter is aligned with the feature and the \emph{absolute} value of the response is maximal; the other two points correspond to the two perpendicular directions.

Because, however, the maximal absolute response may correspond to either a maximum or minimum (depending on whether the underlying feature is light-on-dark or vice versa) the only way to find out which of the two perpendicular directions has maximal absolute value is to evaluate the response at both and choose the direction corresponding to the larger absolute value. As a result, estimating orientation from second-order derivatives becomes a nonlinear problem.

Efficient approximations to computing second-order derivatives of the Gaussian can be achieved through Haar-like approximations to the derivative filters~\cite{Bay_etal_CVIU08} or by approximating the Gaussian filter and applying local finite differences~\cite{Kovesi_DICTA10}.

Note this approach is often reformulated by creating a Hessian matrix with the xx and yy derivates on the lead diagonal and the xy derivatives on the opposing diagonal. Solving this matrix produces eigen vectors with direction theta and thetaN and responses R.

G2D's work on the assumption that when steered to match the orientation of a structure, the response will be large, whilst the response in the perpendicular direction will be near-zero. Thus structures can be distinguished from flat backgrounds (both responses near-zero) or circular blob-like structures (both responses large). Equation () (or its Hessian reformulation) provides an elegant solution for determining this orientation analytically, from which the responses can be used to detect structure directly []. Alternatively the filters may be steered to multiple orientations over multiple scales and used as features in a machine learning algorithm [].

However, there are two problems in using second derivatives alone. Firstly, a strong edge in the image will produce an "echo" response that cannot be distinguished from the response at the centre of a CLS. This may seem an arbitrary construct; however it is easy find examples in real data. For example, the edge of the optic disc in a retinogram (Fig X) is often misclassified as a vessel, whilst similar artefacts may occur at the edges of lesions or near the pectoral muscle in mammograms.

Secondly, due to noise in the image, the symmetric profile of a CLS may be disrupted to the extent that not only does the equation [] produce inaccurate results, the responses themselves hold no usual information that a machine learning algorithm to take advantage of. Again, this can be seen clearly in real data, particularly in structures that have a width of only one or two pixels, such as the smallest vessels in retinograms.

The first problem tells us that it is not enough to only have filters designed to match the shape profile of the CLS we want to detect if such filters cannot distinguish other structures in the image background. The second problem shows we cannot rely on the assumptions we make about the CLS in real images. Combining both ideas motivates us to choose a filter bank that more generally represents an image. Our goal then is not to make a priori assumptions about how we want filters to respond to particular structures, but simply to ensure the set of filter responses produce a unique signature for differing structures. It is then up to our chosen machine learning algorithm to match the various signatures present in the training data to the output measure of interest.

Returning to Gaussian derivatives, we note the cause of both problems is that at a given scale and orientation, we can only compute the response to a filter with even symmetry. An intuitive solution is to supplement these filters with Gaussian 1st derivatives (as used most commonly in edge detection e.g. Canny) as used to heuristically discard edge echo responses in []. However, we prefer the solution recommended in [], using the Hilbert transform of the second derivatives. A steerable response can be computed from four separable basis filters, defined below:

The advantage of using Rh rover first derivatives is that it allows us to represent the responses as magnitude and phase:

We show in section X how this improves results, particularly for orientation (and width?) prediction.

\subsubsection{Gabor derivatives}
\label{s:filtering_gabor}
Next we consider Gabor filters.

A Gabor filter pair consists of one sine and one cosine function, in 2 dimensions and windowed with a Gaussian function. They are therefore directionally sensitive, and can also recover phase information from the underlying image region.

Because Gabor filters recover both orientation and phase information, they are a popular choice of filter in image processing applications~\cite{Daugman_TASSP88}. In general, however, they are neither separable nor steerable, although methods to approximate steerability have been explored~\cite{Teo_1987,Perona_PAMI95}. Therefore, they must be applied exhaustively over a discrete set of orientations which makes them expensive in terms of computation and (if all responses are to be stored simultaneously) memory.

%
\begin{equation}
g_{re}(x,y;\lambda,\theta,\sigma,\gamma) = \exp(-\frac{x'^2 + \gamma^2 y'^2}{2\sigma^2}\cos(2\pi \frac{x'}{\lambda})
\label{e:gabor_real}
\end{equation}
\begin{equation}
g_{im}(x,y;\lambda,\theta,\sigma,\gamma) = \exp(-\frac{x'^2 + \gamma^2 y'^2}{2\sigma^2}\sin(2\pi \frac{x'}{\lambda})
\label{e:gabor_imag}
\end{equation}
\begin{align}
x' = x\cos\theta + y\sin\theta \\
%
y' = -x\sin\theta + y\cos\theta
\label{e:gabor_xy}
\end{align}
%

As with Gaussian derivatives, these have been used extensively in detecting CLS, although again often only the even filter [eq X] is used as this is what is assumed will match the shape. For the same reason we match G2 with its Hilbert pair, we recommend using both odd and even parts, with maximum benefits obtained by combining them as a magnitude/phase pair and show experimentally the advantages of doing so in section X.

Note that unlike Gaussian derivatives, Gabor filters are neither separable nor steerable, making them much more expensive to compute. In contrast we now consider two further filtering schemes designed to measure magnitude and phase across and orientation and scale more efficiently: the monogenic signal; Gabor wavelets~\cite{Daugman_TASSP88}; and the Dual Tree Complex Wavelet Transform (\dtcwt{}~\cite{Kingsbury_PTRSLA99}), so far unexploited in applications analysing curvilinear structure.


\subsubsection{The Monogenic Signal}
\label{s:filtering_monogenic}
The monogenic signal~\cite{Felsberg_Sommer_TSP01} computes phase and orientation at a given image location using three filters: one even band-pass filter $B$, and an odd quadrature pair of filters $h_x(x,y) = x/f(x,y)$ and $h_y(x,y) = y/f(x,y)$ where $f(x,y) = 2\pi(x^2 + y^2)^{\frac{3}{2}}$ (\fref{f:filters_monogenic}). These filters are combined to compute local amplitude~($A$), phase~($\psi$) and orientation~($\theta$) at every location in the image:

\begin{align}
A       &= \sqrt{{I_B}^2 + {I_{hx}}^2 + {I_{hy}}^2}
\label{e:monogenic_amplitude} \\
%
\psi	  &= \tan^{-1}\left[ \frac{I_B}{\sqrt{{I_{hx}}^2 + {I_{hy}}^2}} \right]
\label{e:monogenic_phase} \\
%
\theta  &= \tan^{-1}\left[ \frac{I_{hy}}{I_{hx}} \right]
\label{e:monogenic_orientation}
\end{align}

\noindent where $I_B = I \ast B$, $I_{hx} = h_x \ast I_B$ and $I_{hy} = h_y \ast I_B$.

The local amplitude provides a magnitude of response that is consistent for all structures and orientations while the local phase provides a measure of symmetry (in a profile of the structure perpendicular to its orientation), varying from $-\pi/2$ for a negative line (\ie~a dark line on a light background), through $0$ for an edge, to $\pi/2$ for a positive line.

Though the monogenic signal combines both odd and even filters, the even filter $B$ is isotropic and therefore has no directional sensitivity. All orientation information therefore comes from the odd filters $h_x$ and $h_y$, such that orientation is not recovered for symmetric image features (\eg~at the centre of a bar or ridge).

\subsubsection{The Dual-tree Complex Wavelet Transform}
\label{s:filtering_dtcwt}

The Dual-Tree Complex Wavelet Transform (\dtcwt{}~\cite{Kingsbury_ACHA01}) is a directionally selective representation that combines the strengths of approximately shift-invariant coefficient magnitudes and local phase information with the computational efficiency of decimation (\ie~downsampling the image rather than increasing the filter size).

For a given pixel at a given scale, the \dtcwt{} combines the responses to a pairs of wavelets -- one real, one complex, and differing in phase by $90\deg$~(\fref{f:filters_dtcwt}) -- at six orientations: $\pm 15\deg$, $\pm 45\deg$ and $\pm 75\deg$. Because these filters are not exactly rotationally symmetric, the wave frequencies of the $\pm 45\deg$ sub-bands must be reduced so that they lie closer to those at $\pm 15\deg$ and $\pm 75\deg$, and all six sub-bands are adjusted so that the phase at the centre of the impulse response of each wavelet is zero~\cite{Kingsbury_ECSP06}.

% Multiresolution filtering
To compute filter responses at different scales, the image is repeatedly downsampled by a factor of two in every axis before applying the same six filter pairs again. To get the response for every scale at a given location on the original pixel grid, filter responses on a coarse grid at lower levels of the tree are interpolated with a bandpass method~\cite{Anderson_etal_ICIP05}.

% Advantages
The \dtcwt{} has the benefit of a low redundancy of just 4:1, making it feasible to store the decomposition of even large images. It is also efficient, relative to other methods such as Gabor filtering, through its use of downsampling.

% Disadvantages
Decimation does, however, introduce complications because the filters are not necessarily computed centrally over structures of interest. The phase of \dtcwt{} coefficients within the support of a structure therefore encodes both the symmetry of the structure and a spatial offset. By computing phase differences both spatially and across scale, however, it is possible both to recover local phase that is globally consistent for structure symmetry (and analogous to the phase returned from the monogenic signal) and to compute local orientation analytically~\cite{Anderson_ICIAR05,Anderson_SSP05}.

It is not clear, however, how to use responses to the \dtcwt{} filters to compute a single measure of curvilinear structure probability. Though we could select the maximum of the six oriented sub-band coefficients at each scale and combine them in a measure of phase congruency (as in a method based on the monogenic signal~\cite{Wai_etal_MICCAI04}), this would discard potentially useful information.

We therefore construct a feature vector that characterises each pixel by sampling \dtcwt{} coefficients from the six oriented sub-bands in each of the $s$ finest decomposition scales from a neighbourhood centred on the pixel, and transforming every complex response, $c$, to polar coordinates (\ie~magnitude, $|c|$, and angle, $\angle c$). Since orientation is only defined up to a rotation of $180^\circ$, however, the sign of the angle is arbitrary and so we use its absolute value, $|\angle c|$.

\subsubsection{Other stuff}
\label{s:filtering_extras}
Finally we acknowledge that there are of course many further filter banks we do not test in this paper, and for which an exhaustive comparison of results is unfeasible. However, we show that it is the properties we choose to implement for a given a filter bank (e.g. a magnitude/phase versus just an even/odd response, decimation versus increasing filter size, oversampling scales etc.) rather than the inherent properties of the filters that have the biggest effect in performance. In turn, given a set computational cost, this allows us to make an informed choice of suitable filter bank for any given data.

We also show that a filter bank selected given these general criteria can produce features that outperform features handcrafted for a particular application.

One interesting concept we do not test is the idea of learning an optimal set of arbitrary filters for a given set of images, as in []. However, we believe that such an approach is only beneficial if the filters are optimised with respect to the task they need to perform (in our case and in [], separating the responses for CLS and background pixels within a classifier) and cannot see how optimising with respect to some other task (such as reconstructing the image in a maximally sparse way) is intrinsically a desirable thing to do. That said a comparison with the results in [] would be desirable if quantitative results on the DRIVE and STARE datasets were made available.

\subsection{Composing feature vectors from filter responses}
\label{s:composing_features}
In this section we consider how, for any pixel, to combine the responses of a given filter bank into a feature vector. In the simplest form, we just concatenate the responses from the raw filters at all scales and orientations, however we also consider the following:

\subsubsection{Steering}
\label{s:composing_features_steering}
For the Gaussian derivatives (and their Hilbert transform), we can choose to steer the raw responses at each scale to a fixed set of directions spread evenly across the circle (e.g. in the same directions we apply the Gabor filterbank). This potentially produces features that can be more easily matched to the appropriate output measure and for experimentation purposes provides a more direct comparison to the Gabor and \dtcwt{} filter banks.

\subsubsection{Complex form}
\label{s:composing_features_complex}
As discussed in the previous section, for the Gaussian, Gabor and \dtcwt{} filter banks at a given scale and orientation we have a pair of responses that can be thought of as a complex number, where by custom we use the response to the even filter for the real part and the odd response for its imaginary counterpart. We can then choose either to include the real and imaginary parts as separate dimensions in the feature vectors or represent the pair of responses as magnitude and phase. The latter is arguably a more intuitive way to think of the responses - considering the image profile sampled at a given orientation and scale, the magnitude signifies if a feature is present in this 1D signal, whilst the phase tells us about the shape of the feature as it varies from a valley, to a step, to a ridge. Note also that if an image is rotated through 180 degrees, a complex response C = a+ib becomes C*=a-ib. Thus if we want to make our features responses ambivalent to 180 degree rotations we can use the absolute value of the imaginary part when computing phase.

\subsubsection{Rotation invariance}
\label{s:composing_features_rotation}
Given a set of responses at orientations spread evenly over the circle, a common approach is to select the orientation with maximal response and circular shift the remaining responses in the feature vector such that the maximal orientation for each feature vector occupies the same dimension. The intention is to produce feature vectors with rotational invariance thus collapsing the size of the feature space (proportional to the number of discrete orientations in the filter bank) and making it easier for the classifier to do its job. Whilst theoretically appealing we show in section X that this has no discernible benefit in practice. Note also, with responses over multiple scales, we can choose either to allow the responses in each scale to shift independently or choose a single maximum orientation (e.g. from the scale that produces maximum response) to circularly shift all scales. Here we take the former approach although we have experimented with both and found little difference in performance.

\subsubsection{Pooling neighbourhood responses}
\label{s:composing_features_neighbours}
In contrast to faffing with rotational invariance, a simple yet effective measure is to pool the responses from neighbouring pixels. Again we have experimented with more exotic sampling schemes in which we interpolate responses in a circular pattern about the pixel of interest, but have found that in practice simply sampling a 3x3 window of responses provides most benefit. Of course this increases the dimension of the feature vectors nine-fold, but with machine learning algorithms (such as random forests) designed to cope with large dimensional features and plenty of training data (which is nearly always the case in this set up given each pixel in an image is a sample and thus even a small set of images typically contain millions of samples) this needn't be a problem.

Flow chart…


\clearpage
\section{Target Output Labels}
Our approach to analyzing and understanding images containing linear structure is to use statistical learning methods to recognize patterns present in training data in order to predict useful information in previously unseen images. More specifically, we focus on three tasks: detecting linear structures in the image; discriminating between linear structures of different types (\eg~classifying ducts from spicules in mammograms); and measuring the orientation of linear structures. Though the input image features are common across all three tasks, the output label we wish to predict is task-dependent.

\subsection{Detecting Linear Structure}
\input{why/detect_lines/in_general}
\input{output_labels/label_detection}%

\subsection{Classifying Linear Structure}
\input{why/classify_lines/in_general}%
\input{why/classify_lines/in_mammograms}%
\input{output_labels/label_classification}%

\subsection{Measuring Orientation}
\label{s:measuring_orientation}
\input{why/measure_orientation/in_general}%
To address this problem, we assume that orientation can be expressed as a (typically nonlinear) function of the responses to a given set of filters. Theoretically, we know this to be true for some filter banks (\eg~second derivatives of a Gaussian), though there are some complications.

First, when filters are applied at more than one scale we must ensure that we use the responses from the best scale for the true line width; analytic methods~\cite{Karssemeijer_teBrake_TMI96,Mei_etal_IVC09} assume this is the scale with the greatest response, though this is not guaranteed in the presence of noise. Second, any analytic method that assumes noise to be additive and Gaussian may suffer when this is not the case; this is a particularly a risk in medical applications (\eg~ultrasound has multiplicative Rayleigh noise). Third, for some filter banks (such as the \dtcwt{}) an analytic solution is not available at all or is fiendishly complex at best.

\input{output_labels/label_orientation}


\clearpage
\section{Statistical Learning Methods}
Given a set of filter-bank outputs from different scales, the second step in estimating orientation is to combine them in some way. There are two basic approaches: to find the scale at which the total magnitude of response is greatest, and combine the different filter responses at that scale analytically~\cite{Karssemeijer_teBrake_TMI96,Mei_etal_IVC09}; or to use a regression learning approach to combine the filter responses across all scales and orientations~\cite{Berks_etal_IPMI11}.

In this work, we consider three classifiers of varying complexity: a linear classifier; a boosted classifier; and a Random Forest.

\subsection{Linear Classification}
\label{s:learning_linear}
\input{methods/machine_learning/linear_regression/regression_linear.tex}

%\subsection{Logistic Classification}
%\label{s:learning_logistic}
%\input{regression_logistic}

\subsection{Boosted Learning}
\label{s:learning_boosted}
\input{methods/machine_learning/boosting/regression_boosted.tex}%

\subsection{Random Forests}
\label{s:learning_forest}
\input{methods/machine_learning/decision_trees/rf_tree.tex}
\input{methods/machine_learning/random_forests/rf_background.tex}
\input{methods/machine_learning/random_forests/rf_detection.tex}
\input{methods/machine_learning/random_forests/rf_orientation.tex}%

Considering that curvilinear structure has a well-defined orientation, the confidence in an orientation estimate can also be used as a substitute for detection.

\subsection{Sampling Data}
\label{s:learning_sampling_data}
The final step in our method is to determine how we sample data for the forests. We have two schemes, one for running experiments on training data (e.g. to evaluate parameter options), the other for making final predictions on test data.
In the first scheme, we simply take some fixed size random subsample of pixels across the whole training data, with an equal number of background and foreground pixels (although only the foreground pixels are used orientation and width prediction). We then take a bootstrap sample of this data to train each tree in the forest. To test the forest, we take a second subsample from the pixels in the main training data not used in the first set. We can repeat this scheme, taking different random subsamples at every iteration, to compute a measure of uncertainty in prediction performance.
To make final predictions on the test data, we adopt a slightly more complicated sampling scheme that aims to better use all the data in the training set. In the first stage, we sample a different random subset of the training data for each tree during forest building, recording which pixels were selected. We then use the forest to predict all the training data, where at each pixel we aggregate only those predictions from trees for which the pixel wasn't selected. We can thus produce an unbiased prediction error at each pixel, analogous to the out-of-bag error described in Breiman's original random forest work [].
We then build a second forest, where again we sample a different random subset of the training data for each tree, only this time rather than uniformly sampling from the data, we weight the samples according to equation X,
%
\begin{equation}
Er = x
\label{e:reweight_sampling}
\end{equation}
%
where Ep is the prediction error described above and is defined separately for detection, orientation and width prediction as follows:
%
\begin{align}
E   &= a
\label{e:reweight_detect} \\
%
E	&= b
\label{e:reweight_orientation} \\
%
E   &= c
\label{e:reweight_width}
\end{align}
%
This has the effect of oversampling pixels that were poorly predicted in the first forest (with lambda controlling the level of oversampling versus uniform sampling) and results in a significant improvement in overall prediction performance. Note that the second stage of this process can be repeated to determine a suitable value for lambda. Indeed subject to time constraints, we could iterate until our predictions in the training data converge. In practice however, we evaluate performance for a fixed set of values for lambda and select the best.
The resulting forest can then be used to make predictions for all images in the test data.


\clearpage
\section{Data \& Applications}
We evaluate our methods on three real datasets, two of which containing retinograms and the third containing images of the?. These data are described below.
%
\subsection{DRIVE}
\label{s:dataset_drive}
%
\input{what_is/diabetic_retinopathy}

\input{why/detect_lines/in_retinograms}

\input{why/measure_orientation/in_retinograms}
%

The publicly available DRIVE dataset~\cite{Staal_etal_TMI04} contains 40 full colour, JPEG compressed retinogram images (\fref{f:retinography}a) that originate from a diabetic neuropathy screening program in The Netherlands, where subjects were aged 25-90. The images were acquired using a Canon CR5 non-mydriatic 3CCD camera with a 45 degree field of view (FOV) and 8 bits per colour plane, and are $768 \by 584$ pixels in size. The field of view is defined by a mask, provided with every image, that results in a cropped image $565 \by 584$ pixels in size.

Forty images from a total of 400 were selected for the dataset, seven of which exhibit signs of mild early diabetic retinopathy. These 40 are split into 20 training and 20 test images. Every image comes with at least one mask (test images have two), hand-labelled by human observers, that define ground truth vessel segmentations (\fref{f:fig_drive_examples}).

\subsection{STARE}
\label{s:dataset_stare}
STARE is basically the same as DRIVE. What more can I say?

\subsection{Fibre}
\label{s:dataset_stare}

\subsection{Synthetic images}
\label{s:dataset_synthetic}

In addition, we use synthetic data to explicate particular points discussed in section X. Each synthetic image is created as follows:
Generate a line of random direction, contrast and width, with elliptical profile centred in 64x64 background. The background may either be flat or containing an edge of random orientation and contrast. The image is then corrupted by signal dependent Rician noise, subject to equation X.
%
\begin{equation}
I_{noise} = I
\label{e:rician_noise}
\end{equation}
%


\clearpage
\section{Experiments \& Results}
\label{s:experiments}

We first show use sets of synthetic data with increasing noise to highlight the benefit of learning to predict orientation as opposed to relying on analytical methods (we take it as given now that learning is established as superior to analytical methods for detecting structure), and to examine the benefit of using both odd and even filters.
We then test all combinations of composing feature vectors from our four filter banks using subsamples of the training data for each real dataset.
Finally, we use the best performing feature vector composition and construct forests to apply to the test data for the DRIVE (and STARE?) data as described in section X, and compare the results to previous work.

\subsection{Experiment 1: Synthetic data, increasing noise}
\label{s:experiments_1}
Figures:
\begin{itemize}
  \item Percentage of correctly selected oriented sub-band as noise increases
  \item Percentage of correctly selected scale as noise increases
  \item Overall Gaussian prediction error
  \item The same for DRIVE data
  \item Performance for individual scales
\end{itemize}
%	
Key point: analytic solutions don't effectively compile information of all scale - you are better off picking a single scale. In contrast, learning methods improve as all scales are included. Note also that including all scales provides a more consistent performance over structures of all widths*

\subsection{Experiment 2: Synthetic data, Line vs Edge }
\label{s:experiments_2}
[may leave out or combine with 1]
%
\begin{itemize}
  \item Line detection when on edge: with/without odd component, 1x1 vs 3x3
  \item Performance specifically at edge:

  %
  \begin{itemize}
    \item Show figure on synthetic data
    \item Real example from DRIVE data
  \end{itemize}
  %
\end{itemize}
%
\begin{figure}[t]
\centering
\begin{tabular}{@{}c c c@{}}
\includegraphics[width=0.3\columnwidth]{\figpath/retina/02_optic} &
\includegraphics[width=0.3\columnwidth]{\figpath/retina/02_optic_g2d_inv} &
\includegraphics[width=0.3\columnwidth]{\figpath/retina/02_optic_g12d_inv} \\
%\includegraphics[height=0.15\textheight]{\figpath/retina/002_abs_error} \\
(a) & (b) & (c) \\
\noalign{\smallskip}
\end{tabular}
%
\caption{Detecting vessels in retinography: %
(a) Magnified region containing optic disk; %
(b) Segmentation using only even filter responses as features: the false positive predictions
at the edge of the disk have similar strength to neighbouring vessels; %
(c) Segmentation using odd and even filter responses: false positives are still present, but at a
much lower strength to nearby vessels;
}
\label{f:retinography}
\end{figure}

\subsection{Experiment 3: Comparing Filters banks and Feature Vector Compositions}
\label{s:experiments_3}
Experiment 3 - real data, all permutations of composing feature vectors
%
\begin{table*}[t]
\centering
\small
\input{experiments/tab_DRIVE_training_1.tex}
\caption{Detecting and predicting the orientation of retinal vessels. DRIVE database, training images:
effect of pooling neighbourhood filter responses.}
\label{t:drive_training_1}
\end{table*}
%
\begin{table*}[t]
\centering
\small
\input{experiments/tab_DRIVE_training_cost.tex}
\caption{Detecting and predicting the orientation of retinal vessels. DRIVE database, training images:
effect of pooling neighbourhood filter responses.}
\label{t:drive_training_c}
\end{table*}
%
\begin{table*}[t]
\centering
\small
\input{experiments/tab_fibre_training_cost.tex}
\caption{Detecting and predicting the orientation of retinal vessels. DRIVE database, training images:
effect of pooling neighbourhood filter responses.}
\label{t:fibre_training_c}
\end{table*}
%
\begin{table}[h]
\centering
\small
\input{experiments/tab_DRIVE_training_2.tex}
\caption{Detecting and predicting the orientation of retinal vessels. DRIVE database, training images:
effect of feature vector composition}
\label{t:drive_training_2}
\end{table}
%
\begin{table}[h]
\centering
\small
\input{experiments/tab_DRIVE_training_3.tex}
\caption{Detecting and predicting the orientation of retinal vessels. DRIVE database, training images:
effect of pooling responses from all scales}
\label{t:drive_training_3}
\end{table}
%
%
\begin{table*}[t]
\centering
\small
\input{experiments/tab_fibre_training_1.tex}
\caption{Detecting and predicting the orientation of nerve fibres in confocal corneal microscopy images. Training images:
effect of pooling neighbourhood filter responses.}
\label{t:fibre_training_1}
\end{table*}
%
\begin{table}[h]
\centering
\small
\input{experiments/tab_fibre_training_2.tex}
\caption{Detecting and predicting the orientation of nerve fibres in confocal corneal microscopy images. Training images:
effect of feature vector composition.}
\label{t:fibre_training_2}
\end{table}
%
\begin{table}[h]
\centering
\small
\input{experiments/tab_fibre_training_3.tex}
\caption{Detecting and predicting the orientation of nerve fibres in confocal corneal microscopy images. Training images:
effect of pooling responses from all scales.}
\label{t:fibre_training_3}
\end{table}
%
Key points:

%
\begin{itemize}
  \item Overall:
  \begin{itemize}
    \item Detection: Gabor = Gaussian > \dtcwt{} > Monogenic
    \item Orientation: Gabor > \dtcwt{} > Gaussian > Monogenic
    \item Hypothesise that this is due to Gabor being more directionally selective than Gaussian (see figure X)
  \end{itemize}

  \item Steering:
  \begin{itemize}
    \item Yes, this benefits Gaussian coefficients
  \end{itemize}

  \item Including odd/even filters

  \begin{itemize}
    \item Yes, benefits Gabor and Gaussian filters (for \dtcwt{} it is particularly necessary as neither filter is completely odd or even, thus neither is an ideal match for the majority of data)
    \item Benefit particularly noticeable in predicting orientation
    \item Converting to magnitude/phase further benefit orientation prediction
    \item Conjugate phase also improves orientation prediction
  \end{itemize}

  \item Rotation invariance

  \begin{itemize}
    \item No significant benefit for Gaussian and Gabor
    \item Significantly worse for \dtcwt{} (because bands are not rotationally identical see figure X)
  \end{itemize}

  \item Pooling neighbourhood responses

  \begin{itemize}
    \item Always benefits, regardless of test
    \item Allows filters with odd symmetry to approximate performance of filters with even symmetry
    \item Increases size of feature vector (and hence tree training and predicting time) but doesn't include additional filtering overhead
  \end{itemize}

  \item Pooling over all scales
  \begin{itemize}
    \item Always benefits, regardless of test
    \item Produces consistent prediction across structures of all size: using just filters from "middle scales" may give similar performance averaged over the whole set, but performs significantly worse for fine structures
  \end{itemize}

  \item Oversampling scale and orientation
  \begin{itemize}
    \item Has benefit, though tiny margins for detection
    \item Scale more beneficial than orientation
    \item Can be very expensive computationally (not really possible on a standard PC)
  \end{itemize}

  \item Putting all filters together
  \begin{itemize}
    \item Benefit, but less so than oversampling scale (see above) which is marginally cheaper and requires less memory
  \end{itemize}

  \item Comparing datasets
  \begin{itemize}
    \item STARE and DRIVE very similar
    \item As expected, FIBRE harder than both
  \end{itemize}
\end{itemize}
%

\subsection{Experiment:4 - Bang, the real thing}
\label{s:experiments_4}
%
\begin{table}[h]
\centering
\small
\input{experiments/tab_DRIVE_test.tex}
\caption{Final detection and orientation prediction results for retinogram vessels.}
\label{t:ret_test}
\end{table}
%
\begin{table}[h]
\centering
\small
\input{experiments/tab_fibre_test.tex}
\caption{Final detection and orientation prediction results for fibres in CCM images.}
\label{t:fibre_test}
\end{table}
%
\begin{figure*}[t]
\centering
\begin{tabular}{@{}c c c c c@{}} % @{} removes padding around the edge of the table
\includegraphics[width=0.18\textwidth]{figs/retina/19_DRIVE_ret} &
\includegraphics[width=0.18\textwidth]{figs/retina/19_DRIVE_segmentation_gabor_inv} &
\includegraphics[width=0.18\textwidth]{figs/retina/19_DRIVE_segmentation_gh2da_inv} &
\includegraphics[width=0.18\textwidth]{figs/retina/19_DRIVE_segmentation_mono_inv} &
\includegraphics[width=0.18\textwidth]{figs/retina/19_DRIVE_segmentation_dt_inv} \\
(a) & (b) & (c) & (d) & (e) \\
\noalign{\smallskip}
%
\includegraphics[width=0.18\textwidth]{figs/retina/08_DRIVE_ret} &
\includegraphics[width=0.18\textwidth]{figs/retina/08_DRIVE_segmentation_gabor_inv} &
\includegraphics[width=0.18\textwidth]{figs/retina/08_DRIVE_segmentation_gh2da_inv} &
\includegraphics[width=0.18\textwidth]{figs/retina/08_DRIVE_segmentation_mono_inv} &
\includegraphics[width=0.18\textwidth]{figs/retina/08_DRIVE_segmentation_dt_inv} \\
(f) & (g) & (h) & (i)  & (j) \\
\noalign{\smallskip}
\end{tabular}
%
\caption{Detecting vessels in retinography: Best (a-e) and worst (f-j) results in the test set. %
(a,f) original image; %
(b,g) Gabor; %
(c,h) Gaussian; %
(d,i) Monogenic Signal; %
(e,j) \dtcwt; %
}
\label{f:drive_segmentations}
\end{figure*}
%
\begin{figure*}[t]
\centering
\begin{tabular}{@{}c c c c c@{}} % @{} removes padding around the edge of the table
\includegraphics[width=0.18\textwidth]{figs/fibre/03_fibre_ccm} &
\includegraphics[width=0.18\textwidth]{figs/fibre/03_fibre_segmentation_gabor_inv} &
\includegraphics[width=0.18\textwidth]{figs/fibre/03_fibre_segmentation_gh2da_inv} &
\includegraphics[width=0.18\textwidth]{figs/fibre/03_fibre_segmentation_mono_inv} &
\includegraphics[width=0.18\textwidth]{figs/fibre/03_fibre_segmentation_dt_inv} \\
(a) & (b) & (c) & (d) & (e) \\
\noalign{\smallskip}
%
\includegraphics[width=0.18\textwidth]{figs/fibre/51_fibre_ccm} &
\includegraphics[width=0.18\textwidth]{figs/fibre/51_fibre_segmentation_gabor_inv} &
\includegraphics[width=0.18\textwidth]{figs/fibre/51_fibre_segmentation_gh2da_inv} &
\includegraphics[width=0.18\textwidth]{figs/fibre/51_fibre_segmentation_mono_inv} &
\includegraphics[width=0.18\textwidth]{figs/fibre/51_fibre_segmentation_dt_inv} \\
(f) & (g) & (h) & (i)  & (j) \\
\noalign{\smallskip}
\end{tabular}
%
\caption{Detecting fibres in CCM images: Best (a-e) and worst (f-j) results in the test set. %
(a,f) original image; %
(b,g) Gabor; %
(c,h) Gaussian; %
(d,i) Monogenic Signal; %
(e,j) \dtcwt; %
}
\label{f:fibre_segmentations}
\end{figure*}
%
%
\begin{figure}[t]
\centering
\begin{tabular}{@{}c c@{}} % @{} removes padding around the edge of the table
\includegraphics[width=0.48\columnwidth]{figs/retina/34_DRIVE_ret} &
\includegraphics[width=0.48\columnwidth]{figs/retina/34_resampling_difference} \\
(a) & (b) \\
\noalign{\smallskip}
\end{tabular}
%
\caption{What effect does resampling have? %
(a) Retinogram; %
(b) Difference between prediction maps with and without resampling. Red indicates a reduced vessel probability with resampling, blue an increased vessel probability. Note the reduced prediction probability at the edge of vessels and for the false predictions caused by pathology in the image; %
}
\label{f:retinography}
\end{figure}
%
%
\begin{figure}[t]
\centering
%
\includegraphics[width=0.9\columnwidth]{figs/retina/DRIVE_test_detection_roc_zoom}
%
\caption{Detecting vessels in retinography: DRIVE test ROCs %
}
\label{f:retinography}
\end{figure}
%
%
\begin{figure}[t]
\centering
%
\includegraphics[width=0.9\columnwidth]{figs/retina/DRIVE_test_orientation_cdf}
%
\caption{Predicting vessel orientation in retinography: DRIVE database %
}
\label{f:retinography}
\end{figure}
%
\begin{figure}[t]
\centering
%
\includegraphics[width=0.9\columnwidth]{figs/retina/STARE_detection_roc_zoom}
%
\caption{Detecting vessels in retinography: STARE ROCs %
}
\label{f:retinography}
\end{figure}
%
\begin{figure}[t]
\centering
\includegraphics[width=0.9\columnwidth]{figs/retina/STARE_orientation_cdf}
%
\caption{Predicting vessel orientation in retinography: STARE database %
}
\label{f:retinography}
\end{figure}
%

\begin{itemize}
  \item DRIVE

  \begin{itemize}
    \item State of the art detection
    \item Orientation?
  \end{itemize}

  \item STARE
  \begin{itemize}
    \item Classify using DRIVE, still good performance
  \end{itemize}

  \item Fibre
  \begin{itemize}
    \item Thin and allow tolerance as per Dabbah paper
  \end{itemize}

\end{itemize}

\clearpage
\section{Discussion}

\begin{itemize}
  \item Using confidence in orientation prediction

  \begin{itemize}
    \item Possible uses
    \item Figure?
  \end{itemize}

  \item Not mentioned centreline


\end{itemize}

\input{discussion.tex}


\clearpage
\section{Conclusions}
\input{conclusions.tex}


\section*{Acknowledgements}
We thank Nick Kingsbury for the \dtcwt{} Matlab toolbox. Mammograms were provided by the Nightingale Breast Centre, South Manchester University Hospitals Trust, UK and were annotated by Dr Caroline Boggis and Dr Rumana Rahim. This work was funded by EPSRC grant EP/E031307/1.

\bibliographystyle{plain}
\bibliography{%
./bib/_aliases,%
./bib/mobio,%
./bib/mammography,%
./bib/ml,%
./bib/nailfold,%
./bib/papers_by_year,%
./bib/local}

\end{document} 